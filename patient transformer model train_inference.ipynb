{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from exp.misc import *\n",
    "from exp.ProcessData import *\n",
    "from exp.PytorchModels import *\n",
    "from exp.LearnerClass import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "import PIL.Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torchvision.transforms.functional as TF\n",
    "from types import MethodType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=json_to_parameters('config.json')\n",
    "num_folds=3\n",
    "SEEDS=[220,432,8153]\n",
    "add_seed=2000\n",
    "add_seed_orig=3000\n",
    "add_seed_cv=200\n",
    "add_seed_test=300\n",
    "model_type='tf_efficientnet_b3_ns'\n",
    "base_name_tamplate='image_mlps_cut_128_seed_fullv{}'\n",
    "name_tamplate='image_mlps_cut_128_seed_fullv{}_transformer_sample'\n",
    "name_tamplate_orig='image_mlps_cut_128_seed_fullv{}_transformer_sample_origonly_rand23'\n",
    "output_name=f'{model_type}_image_mlps_cut_128_seed_fullv_transformer_sample_origonly_rand23_predict.pth'\n",
    "device = device_by_name('Tesla')\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(params.path.data+'train.csv')\n",
    "extra_df=pd.read_csv(params.path.data+'isim2019.csv')\n",
    "train_df=pd.concat([train_df, extra_df], ignore_index=True,sort=False)\n",
    "prepare_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metric(y_pred,y_true):\n",
    "    y_true=(y_true==1).reshape(-1)\n",
    "    y_pred=y_pred.reshape(-1,y_pred.shape[-1])[y_true>=0]\n",
    "    y_true=y_true[y_true>=0]==1\n",
    "\n",
    "    preds=torch.sigmoid(torch.tensor(y_pred[:,1],dtype=torch.float32)).numpy()\n",
    "    preds1=F.softmax(torch.tensor(y_pred,dtype=torch.float32),-1)[:,1].numpy()\n",
    "    preds2=0.5*preds1/preds1.std()+0.5*preds/preds.std()\n",
    "    return {'metric':-roc_auc_score(y_true, preds1),'metric1':-roc_auc_score(y_true, preds),\n",
    "                                                                'metric2':-roc_auc_score(y_true, preds2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLoss():\n",
    "    def __init__(self,nom_size=0.5):\n",
    "        self.nom_size=nom_size\n",
    "    def __call__(self,y_pred,y_true):\n",
    "        y_true=y_true.reshape(-1)\n",
    "        y_pred=y_pred.reshape(-1,y_pred.shape[-1])\n",
    "        return F.cross_entropy(y_pred,y_true,ignore_index=-1)*(y_true!=-1).to(torch.float32).mean()/self.nom_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFocalLoss():\n",
    "    def __init__(self,gamma=2.,nom_size=0.5):\n",
    "        self.nom_size=nom_size\n",
    "        self.loss=FocalCrossEntropy(gamma)\n",
    "    def __call__(self,y_pred,y_true):\n",
    "        y_true=y_true.reshape(-1)\n",
    "        y_pred=y_pred.reshape(-1,y_pred.shape[-1])\n",
    "        k=(y_true!=-1).to(torch.float32).mean()/self.nom_size\n",
    "        y_pred=y_pred[y_true>=0]\n",
    "        y_true=y_true[y_true>=0]\n",
    "        return self.loss(y_pred,y_true)*k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(self,ds,num_workers=8,tta=1,dl_args={'shuffle':False}):\n",
    "    predss=[]\n",
    "    truess=[]\n",
    "    inds=[]\n",
    "    tk = notebook.tqdm(range(tta))\n",
    "    for i in tk:\n",
    "        ds.reset()\n",
    "        y_pred=learner.predict(ds,batch_size=batch_size,num_workers=num_workers,\n",
    "                               return_inds=True,return_true=True,dl_args=dl_args,verbose=False)\n",
    "        predss.append(y_pred[0])\n",
    "        inds.append(y_pred[1])\n",
    "        truess.append(y_pred[2])\n",
    "    prd=[]\n",
    "    y_true=[]\n",
    "    for i,pred in enumerate(predss):\n",
    "        p=pred.reshape(-1,8)\n",
    "        y=truess[i].reshape(-1)\n",
    "        ind = inds[i].reshape(-1)\n",
    "        p=p[ind<ind.max()]\n",
    "        y=y[ind<ind.max()]\n",
    "        ind=ind[ind<ind.max()]\n",
    "        prd.append(p[np.argsort(ind)])\n",
    "        y_true.append(y[np.argsort(ind)])\n",
    "    y_pred=np.nanmean(np.stack(prd,0),0)\n",
    "    y_true=np.nanmean(np.stack(y_true,0),0)\n",
    "    l,m = self.loss_func(torch.tensor(y_pred,dtype=torch.float32),torch.tensor(y_true,dtype=torch.long)), dict() if self.metric is None else self.metric(y_pred,y_true)\n",
    "    tk.disable=False\n",
    "    tk.set_postfix(loss = l.item(), **m)\n",
    "    tk.disable=True\n",
    "    return l,m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 2020 + ISIM2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = 1\n",
    "num_epochs=24 #epoch_in_rep*reps\n",
    "batch_size=64\n",
    "pos_mul=1\n",
    "epoch_mul=1\n",
    "epoch_in_rep=6\n",
    "reps =3\n",
    "num_epochs=epoch_in_rep*reps\n",
    "reps_lr=[1e-4,0.3e-4,1e-5]\n",
    "\n",
    "\n",
    "for SEED in SEEDS:\n",
    "    val_folds, train_folds, patients_val = create_folds_extra(train_df,num_folds,SEED)\n",
    "    for fold in range(num_folds): \n",
    "        dft=train_df.copy()\n",
    "        base_name=params.model_format.format(model_type,base_name_tamplate.format(SEED),v,fold)\n",
    "        fname=params.path.features+(base_name.split('.')[0]+'.pkl')\n",
    "        fname2019=params.path.features+(base_name.split('.')[0]+'_isim2019.pkl')\n",
    "        name=params.model_format.format(model_type,name_tamplate.format(SEED),v,fold)\n",
    "\n",
    "        dft.patient_id=np.where(dft.patient_id=='0',dft.index.values.astype('str'),dft.patient_id)\n",
    "\n",
    "        patients_val=[set(np.unique(dft.patient_id.values[v])) for v in val_folds]\n",
    "        all_patients=set(np.unique(dft.patient_id.values))\n",
    "\n",
    "        patients_train=[all_patients.difference(p) for p in patients_val]\n",
    "\n",
    "        with open(fname,'rb') as f:\n",
    "            features0=pickle.load(f)\n",
    "        with open(fname2019,'rb') as f:\n",
    "            features1=pickle.load(f)\n",
    "        features=torch.tensor(np.concatenate([features0,features1,np.zeros_like(features0[:,[0]])],1),dtype=torch.float32)\n",
    "\n",
    "\n",
    "        ds = PatientFeaturesDataset(features,dft,patients_train[fold],24,min_len=23)\n",
    "        ds_val = PatientFeaturesDataset(features,dft,patients_val[fold],24,min_len=23)\n",
    "        \n",
    "\n",
    "        print(name)\n",
    "\n",
    "        torch.manual_seed(SEED+fold+add_seed)\n",
    "        np.random.seed(SEED+fold+add_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        validate_ds=ds_val\n",
    "        train_ds=ds\n",
    "\n",
    "        model = TransformerModel(256,1024,num_outputs=8,n_heads=4,n_encoders=4).to(device)\n",
    "\n",
    "        my_loss=MyLoss(len(ds)/ds.sex.shape[0])\n",
    "        print(len(ds)/ds.sex.shape[0])\n",
    "\n",
    "        learner = Learner(model,None,loss_func=my_loss,name=name,scheduler=None,device=device)\n",
    "        learner.metric=my_metric\n",
    "\n",
    "        learner.optimizer = torch.optim.Adam(learner.model.parameters(), lr=0.3e-4)\n",
    "        mx=ds.idx_array.max()\n",
    "        num_ids=np.array([(s<mx).sum() for s in ds.idx_array])\n",
    "        learner.sampler=D.WeightedRandomSampler(num_ids,int(num_ids.sum()), replacement=True)\n",
    "        epoch_size=int(1.001*num_ids.sum())\n",
    "        def new_get_y(self,batch):\n",
    "            return batch[-2]\n",
    "        def new_get_inds(self,batch):\n",
    "            return batch[-3]\n",
    "        def new_get_x(self,batch):\n",
    "            return batch[:-3] \n",
    "        def on_epoch_begin(self,*args,**kargs):\n",
    "            train_ds.reset()\n",
    "            mx=train_ds.idx_array.max()\n",
    "            num_ids=np.array([(s<mx).sum() for s in train_ds.idx_array])\n",
    "            self.sampler=D.WeightedRandomSampler(num_ids, int(num_ids.sum()),replacement=True)\n",
    "        learner.get_y=MethodType(new_get_y, learner)\n",
    "        learner.get_x=MethodType(new_get_x, learner)\n",
    "        learner.get_inds=MethodType(new_get_inds, learner)\n",
    "        learner.evaluate=MethodType(evaluate, learner)\n",
    "        learner.on_epoch_begin=MethodType(on_epoch_begin, learner)\n",
    "        for t in range(reps):\n",
    "            train_dl_args={'shuffle': False,'sampler':learner.sampler }\n",
    "            learner.scheduler = torch.optim.lr_scheduler.OneCycleLR(learner.optimizer, pct_start=0.01,final_div_factor= 10,\n",
    "                                                                    max_lr=reps_lr[t], steps_per_epoch=epoch_size//batch_size+1, \n",
    "                                                                    epochs=epoch_in_rep)\n",
    "            learner.fit(epoch_in_rep,train_ds,validate_ds,batch_size=batch_size,eval_batch=2*batch_size,\n",
    "                    path=params.path.models,num_workers=12,send_log=False,train_dl_args=train_dl_args,tta=4)\n",
    "        learner.save_model(params.path.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 2020 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v=1\n",
    "num_epochs=24 #epoch_in_rep*reps\n",
    "batch_size=64\n",
    "pos_mul=1\n",
    "epoch_mul=1\n",
    "epoch_in_rep=8\n",
    "reps =3\n",
    "num_epochs=epoch_in_rep*reps\n",
    "reps_lr=[1e-4,3e-5]\n",
    "ttas=[8,8]\n",
    "\n",
    "dft=train_df[train_df.patient_id!='0'].copy()\n",
    "\n",
    "for SEED in SEEDS:\n",
    "    val_folds, train_folds, patients_val = create_folds_extra(train_df,num_folds,SEED)\n",
    "    for fold in range(num_folds): \n",
    "        dft=train_df[train_df.patient_id!='0'].copy()\n",
    "        base_name=params.model_format.format(model_type,base_name_tamplate.format(SEED),v,fold)\n",
    "        fname=params.path.features+(base_name.split('.')[0]+'.pkl')\n",
    "        name=params.model_format.format(model_type,name_tamplate.format(SEED),v,fold)\n",
    "\n",
    "        patients_val=[set(np.unique(dft.patient_id.values[v])) for v in val_folds]\n",
    "        all_patients=set(np.unique(dft.patient_id.values))\n",
    "\n",
    "        patients_train=[all_patients.difference(p) for p in patients_val]\n",
    "\n",
    "        with open(fname,'rb') as f:\n",
    "            features0=pickle.load(f)\n",
    "\n",
    "        features=torch.tensor(np.concatenate([features0,np.zeros_like(features0[:,[0]])],1),dtype=torch.float32)\n",
    "\n",
    "\n",
    "        ds = PatientFeaturesDataset(features,dft,patients_train[fold],24,min_len=23)\n",
    "        ds_val = PatientFeaturesDataset(features,dft,patients_val[fold],24,min_len=23)\n",
    "\n",
    "\n",
    "        print(name)\n",
    "\n",
    "        torch.manual_seed(SEED+fold+add_seed_orig)\n",
    "        np.random.seed(SEED+fold+add_seed_orig)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        validate_ds=ds_val\n",
    "        train_ds=ds\n",
    "\n",
    "        epoch_size=len(train_ds)\n",
    "        model = TransformerModel(256,1024,num_outputs=8,n_heads=4,n_encoders=4).to(device)\n",
    "\n",
    "        my_loss=MyLoss(0.2) #MyFocalLoss(gamma=0.9,nom_size=0.2)\n",
    "\n",
    "        learner = Learner(model,None,loss_func=my_loss,name=name,scheduler=None,device=device)\n",
    "        learner.metric=my_metric\n",
    "        learner.load_model(params.path.models)\n",
    "        learner.name= params.model_format.format(model_type,name_tamplate_orig.format(SEED),v,fold)\n",
    "        print(learner.name)\n",
    "\n",
    "        learner.optimizer = torch.optim.Adam(learner.model.parameters(), lr=3e-5)\n",
    "\n",
    "        def new_get_y(self,batch):\n",
    "            return batch[-2]\n",
    "        def new_get_inds(self,batch):\n",
    "            return batch[-3]\n",
    "        def new_get_x(self,batch):\n",
    "            return batch[:-3] \n",
    "        learner.get_y=MethodType(new_get_y, learner)\n",
    "        learner.get_x=MethodType(new_get_x, learner)\n",
    "        learner.get_inds=MethodType(new_get_inds, learner)\n",
    "        learner.evaluate=MethodType(evaluate, learner)\n",
    "\n",
    "        def on_epoch_begin(self,*args,**kargs):\n",
    "            train_ds.reset()\n",
    "\n",
    "        learner.on_epoch_begin=MethodType(on_epoch_begin, learner)\n",
    "\n",
    "        for i,lr in enumerate(reps_lr):\n",
    "            learner.set_lr(lr)\n",
    "            learner.fit(epoch_in_rep,train_ds,validate_ds,batch_size=batch_size,eval_batch=2*batch_size,\n",
    "                         path=params.path.models,num_workers=12,send_log=False,tta=ttas[i])\n",
    "        learner.save_model(params.path.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "v =1\n",
    "batch_size=64\n",
    "metrics=[]\n",
    "dft=train_df[train_df.patient_id!='0'].copy()\n",
    "for SEED in SEEDS:\n",
    "    val_folds, train_folds, patients_val = create_folds_extra(train_df,num_folds,SEED)\n",
    "    for fold in range(num_folds): \n",
    "        dft=train_df[train_df.patient_id!='0'].copy()\n",
    "        base_name=params.model_format.format(model_type,base_name_tamplate.format(SEED),v,fold)\n",
    "        fname=params.path.features+(base_name.split('.')[0]+'.pkl')\n",
    "        name= params.model_format.format(model_type,name_tamplate_orig.format(SEED),v,fold)\n",
    "\n",
    "        patients_val=[set(np.unique(dft.patient_id.values[v])) for v in val_folds]\n",
    "        all_patients=set(np.unique(dft.patient_id.values))\n",
    "\n",
    "        patients_train=[all_patients.difference(p) for p in patients_val]\n",
    "\n",
    "        with open(fname,'rb') as f:\n",
    "            features0=pickle.load(f)\n",
    "\n",
    "        features=torch.tensor(np.concatenate([features0,np.zeros_like(features0[:,[0]])],1),dtype=torch.float32)\n",
    "        ds_val = PatientFeaturesDataset(features,dft,patients_val[fold],33,min_len=32)\n",
    "\n",
    "        print(name)\n",
    "        _=torch.manual_seed(SEED+fold+add_seed_cv)\n",
    "        np.random.seed(SEED+fold+add_seed_cv)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        validate_ds=ds_val\n",
    "\n",
    "\n",
    "        model = TransformerModel(256,1024,num_outputs=8,n_heads=4,n_encoders=4).to(device)\n",
    "        my_loss=MyLoss(0.2) #MyFocalLoss(gamma=2,nom_size=0.2)\n",
    "                #my_loss=my_one_loss\n",
    "        learner = Learner(model,None,loss_func=my_loss,name=name,scheduler=None,device=device)\n",
    "        learner.metric=my_metric\n",
    "        m=torch.load(f'{params.path.models}{name}',map_location='cpu')\n",
    "        learner.model.load_state_dict(m)\n",
    "        _=learner.model.to(device)\n",
    "\n",
    "        def on_epoch_begin(self,*args,**kargs):\n",
    "            train_ds.reset()\n",
    "            validate_ds.reset()\n",
    "        def new_get_y(self,batch):\n",
    "            return batch[-2]\n",
    "        def new_get_inds(self,batch):\n",
    "            return batch[-3]\n",
    "        def new_get_x(self,batch):\n",
    "            return batch[:-3] \n",
    "\n",
    "        learner.get_y=MethodType(new_get_y, learner)\n",
    "        learner.get_x=MethodType(new_get_x, learner)\n",
    "        learner.get_inds=MethodType(new_get_inds, learner)\n",
    "        learner.evaluate=MethodType(evaluate, learner)\n",
    "        learner.on_epoch_begin=MethodType(on_epoch_begin, learner)\n",
    "        l,m=learner.evaluate(validate_ds,num_workers=8,tta=16,dl_args={'shuffle':False,'batch_size':batch_size})\n",
    "        metrics.append(m)\n",
    "        metrics[-1]['loss']=l.item()\n",
    "\n",
    "name\n",
    "np.array([m['metric'] for m in metrics ]).mean()\n",
    "np.array([m['metric'] for m in metrics ]).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(params.path.data+'test.csv')\n",
    "prepare_df(test_df)\n",
    "test_df=test_df.reset_index(drop=True)\n",
    "predss=[]\n",
    "inds=[]\n",
    "v=1\n",
    "for SEED in SEEDS:\n",
    "    val_folds, train_folds, patients_val = create_folds_extra(train_df,num_folds,SEED)\n",
    "    for fold in range(num_folds): \n",
    "        base_name=params.model_format.format(model_type,base_name_tamplate.format(SEED),v,fold)\n",
    "        fname=params.path.features+(base_name.split('.')[0]+'_test.pkl')\n",
    "        with open(fname,'rb') as f:\n",
    "            features=pickle.load(f)\n",
    "        features.shape\n",
    "        features=torch.tensor(np.concatenate([features,np.zeros_like(features[:,[0]])],1),dtype=torch.float32)\n",
    "        name= params.model_format.format(model_type,name_tamplate_orig.format(SEED),v,fold)\n",
    "        model = TransformerModel(256,1024,num_outputs=8,n_heads=4,n_encoders=4).to(device)\n",
    "        test_ds= PatientFeaturesDataset(features,test_df,set(test_df.patient_id.unique()),24,min_len=23)\n",
    "        print (name)\n",
    "        my_loss=MyLoss(0.01)\n",
    "        learner = Learner(model,None,loss_func=my_loss,name=name,scheduler=None,device=device)\n",
    "        learner.metric=my_metric\n",
    "        learner.load_model(params.path.models)\n",
    "        learner.init_amp()\n",
    "\n",
    "        def new_get_x(self,batch):\n",
    "            return batch[:-1] \n",
    "        learner.get_x=MethodType(new_get_x, learner)\n",
    "        for i in range(32):\n",
    "            test_ds.reset()\n",
    "            y_pred=learner.predict(test_ds,batch_size=64,num_workers=12,return_inds=True)\n",
    "            predss.append(y_pred[0])\n",
    "            inds.append(y_pred[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prd=[]\n",
    "for i,pred in enumerate(predss):\n",
    "    p=pred.reshape(-1,8)\n",
    "    ind = inds[i].reshape(-1)\n",
    "    p=p[ind<test_df.shape[0]]\n",
    "    ind=ind[ind<test_df.shape[0]]\n",
    "    prd.append(p[np.argsort(ind)])\n",
    "\n",
    "with open(params.path.output+output_name,'wb') as f:\n",
    "    pickle.dump(prd,f,protocol=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(params.path.output+output_name,'rb') as f:\n",
    "    prd=pickle.load(f)\n",
    "\n",
    "\n",
    "y_pred=np.nanmean(np.stack(prd,0),0)\n",
    "\n",
    "preds2=F.softmax(torch.tensor(y_pred,dtype=torch.float32),-1)[:,1].numpy()\n",
    "\n",
    "\n",
    "preds2.min()\n",
    "preds2.max()\n",
    "preds2.std()\n",
    "_=plt.hist(preds2,bins=30)\n",
    "\n",
    "sub=pd.read_csv(params.path.data+'sample_submission.csv')\n",
    "\n",
    "sub['image_name']=test_df['image_name']\n",
    "sub['target']=preds2\n",
    "sub.head(10)\n",
    "sub.to_csv(params.path.output+'/submission116.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
