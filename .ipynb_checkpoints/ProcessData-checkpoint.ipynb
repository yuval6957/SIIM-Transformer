{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import notebook\n",
    "from exp.misc import *\n",
    "import torch\n",
    "import PIL.Image\n",
    "import pydicom\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Dataset\n",
    "class DatasetCat(Dataset):\n",
    "    '''\n",
    "    Concatenate datasets for Pytorch dataloader\n",
    "    The normal pytorch implementation does it only for raws. this is a \"column\" implementation\n",
    "    Arges:\n",
    "        datasets: list of datasets, of the same length\n",
    "    Updated: Yuval 12/10/2019\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,datasets):\n",
    "        '''\n",
    "        Args: datasets - an iterable containing the datasets\n",
    "        '''\n",
    "        super(DatasetCat, self).__init__()\n",
    "        self.datasets=datasets\n",
    "        assert len(self.datasets)>0\n",
    "        for dataset in datasets:\n",
    "            assert len(self.datasets[0])==len(dataset),\"Datasets length should be equal\"\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.datasets[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        outputs = tuple(dataset.__getitem__(idx) for i in self.datasets for dataset in (i if isinstance(i, tuple) else (i,)))\n",
    "        return tuple(output for i in outputs for output in (i if isinstance(i, tuple) else (i,)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prepare_df(df):\n",
    "    df.sex=df.sex.fillna('male')\n",
    "    if 'SOPInstanceUID_grp' in df.columns:\n",
    "        df.SOPInstanceUID_grp=df.SOPInstanceUID_grp.fillna(0)    \n",
    "    if 'patient_id_cnt_enc' in df.columns:\n",
    "        df.patient_id_cnt_enc=df.patient_id_cnt_enc.fillna(2)\n",
    "    df.age_approx=df.age_approx.fillna(45.0)\n",
    "    if 'diagnosis' in df.columns:\n",
    "        diagnosis_dict=defaultdict(lambda :0,[('melanoma',1),('nevus',2),('seborrheic keratosis',3),\n",
    "                                              (\"Basal cell carcinoma\",4),(\"Actinic keratosis\",3),(\"Benign keratosis\",3),\n",
    "                                             (\"Dermatofibroma\",5),(\"Vascular lesion\",6),(\"Squamous cell carcinoma\",7)])\n",
    "        df['diagnosis_num']=df.diagnosis.map(diagnosis_dict)\n",
    "        has_target=df.groupby(by='patient_id')['target'].max().rename('patient_melanoma').reset_index()\n",
    "        df['patient_melanoma']=df.merge(has_target,on='patient_id',how='left')['patient_melanoma']\n",
    "    anatom_site_dict=defaultdict(lambda :0,[('head/neck',1), ('upper extremity',2), ('lower extremity',3), ('torso',4), \n",
    "           ('palms/soles',5), ('oral/genital',6),('anterior torso',4),('posterior torso',4),('posterior torso',4)])\n",
    "    df['anatom_site_num']=df['anatom_site_general_challenge'].map(anatom_site_dict)\n",
    "    df.patient_id=df.patient_id.fillna('0')\n",
    "    patient_ids=df.patient_id.unique()\n",
    "    patient_ids.sort()\n",
    "    df['patient_id_num']=df.patient_id.map(dict(zip(patient_ids,range(len(patient_ids)))))\n",
    "    gp=df[['patient_id','age_approx']].groupby('patient_id')['age_approx'].min().rename('min_age').reset_index()\n",
    "    df['min_age']=df.merge(gp,on='patient_id',how='left')['min_age']\n",
    "    df['years_from_min']=df['age_approx']-df['min_age']\n",
    "    df.years_from_min=df.years_from_min*(df.patient_id!='0')\n",
    "\n",
    "def creat_folds(train_df,num_folds,SEED):\n",
    "    upatient_0=np.sort(train_df[train_df.patient_melanoma==0].patient_id.unique())\n",
    "    upatient_1=np.sort(train_df[train_df.patient_melanoma==1].patient_id.unique())\n",
    "    np.random.seed(SEED)\n",
    "    np.random.shuffle(upatient_0)\n",
    "    np.random.seed(SEED)\n",
    "    np.random.shuffle(upatient_1)\n",
    "    nu0=int(np.ceil(upatient_0.shape[0]/num_folds))\n",
    "    nu1=int(np.ceil(upatient_1.shape[0]/num_folds))\n",
    "    patients_val=[set(np.concatenate([upatient_0[i*nu0:(i+1)*nu0],upatient_1[i*nu1:(i+1)*nu1]])) for i in range(num_folds)]\n",
    "    val_folds=[np.sort(np.where(train_df.patient_id.isin(patients_val[i]))[0]) for i in range(num_folds)]\n",
    "    train_folds=[np.sort(np.setdiff1d(np.arange(train_df.shape[0]),val_folds[i])) for i in range(num_folds)]\n",
    "    return val_folds, train_folds, patients_val\n",
    "\n",
    "def create_folds_extra(train_df,num_folds,SEED):\n",
    "    upatient_0=np.sort(train_df[(train_df.patient_melanoma==0) & (train_df.patient_id!='0')].patient_id.unique())\n",
    "    upatient_1=np.sort(train_df[(train_df.patient_melanoma==1) & (train_df.patient_id!='0')].patient_id.unique())\n",
    "    np.random.seed(SEED)\n",
    "    np.random.shuffle(upatient_0)\n",
    "    np.random.seed(SEED)\n",
    "    np.random.shuffle(upatient_1)\n",
    "    \n",
    "    nu0=int(np.ceil(upatient_0.shape[0]/num_folds))\n",
    "    nu1=int(np.ceil(upatient_1.shape[0]/num_folds))\n",
    "    patients_val=[set(np.concatenate([upatient_0[i*nu0:(i+1)*nu0],upatient_1[i*nu1:(i+1)*nu1]])) for i in range(num_folds)]\n",
    "    nan_val=np.sort(np.where(train_df.patient_id=='0')[0])\n",
    "    np.random.seed(SEED)\n",
    "    nan0=int(np.ceil(nan_val.shape[0]/num_folds))\n",
    "    np.random.shuffle(nan_val)\n",
    "    nan_folds=[nan_val[i*nan0:(i+1)*nan0] for i in range(num_folds)]\n",
    "    val_folds=[np.concatenate([nan_folds[i],np.sort(np.where(train_df.patient_id.isin(patients_val[i]))[0])]) for i in range(num_folds)]\n",
    "    train_folds=[np.sort(np.setdiff1d(np.arange(train_df.shape[0]),val_folds[i])) for i in range(num_folds)]\n",
    "    return val_folds, train_folds, patients_val\n",
    "\n",
    "\n",
    "def calc_enbd_mat(df,features,norm=False,do_max=False,rand_rows=0):\n",
    "    rand_rows=rand_rows if rand_rows>0 else features.shape[0]\n",
    "    features=features if not norm else features/np.linalg.norm(features,  axis=-1, keepdims=True)\n",
    "    gp=df[['image_name','patient_id_num']].groupby('patient_id_num')\n",
    "    embd_mat_mean=torch.zeros((len(gp),features.shape[-1]),dtype=torch.float32)\n",
    "    embd_mat_meanmax=torch.zeros((len(gp),features.shape[-1]),dtype=torch.float32)\n",
    "    embd_mat_maxmean=torch.zeros((len(gp),features.shape[-1]),dtype=torch.float32)\n",
    "    for i,g in enumerate(gp.groups.items()):\n",
    "        idx = g[1].values\n",
    "        b=np.stack([np.random.choice(features.shape[0],rand_rows,replace=False) for i in range(len(idx))])\n",
    "        a=idx.repeat(rand_rows).reshape(-1,rand_rows)\n",
    "        if (idx<features.shape[1]).all():\n",
    "            embd_mat_mean[i]=torch.tensor(features[b,a,:].mean(0).mean(0),dtype=torch.float32)\n",
    "            if do_max:\n",
    "                embd_mat_maxmean[i]=torch.tensor(features[b,a,:].mean(1).max(0),dtype=torch.float32)\n",
    "                embd_mat_meanmax[i]=torch.tensor(features[b,a,:].mean(0).max(0),dtype=torch.float32)\n",
    "            \n",
    "    return  torch.cat([embd_mat_mean,embd_mat_maxmean,embd_mat_meanmax],-1) if do_max else embd_mat_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from PIL import  ImageDraw\n",
    "import torch\n",
    "\n",
    "class MyResize():\n",
    "    def __init__(self,h,w):\n",
    "        (self.h,self.w) = (h,w) if w>h else (w,h)\n",
    "    def __call__(self,img):\n",
    "        iw=img.width\n",
    "        ih=img.height\n",
    "        k1=max(iw,ih)/self.w\n",
    "        k2=min(iw,ih)/self.h\n",
    "        new_shape=(0,0,self.h,self.w) #if iw>ih else (0,0,self.w,self.h)\n",
    "        if ih>iw:\n",
    "            img=TF.to_pil_image(torch.flip(TF.to_tensor(img).permute(0,2,1),(1,)))\n",
    "        return TF.crop(TF.resize(img,int(min(iw,ih)/max(k1,k2))),*new_shape)\n",
    "\n",
    "class MyResize2():\n",
    "    def __init__(self,h,w):\n",
    "        (self.h,self.w) = (h,w) if w>h else (w,h)\n",
    "    def __call__(self,img):\n",
    "        iw=img.width\n",
    "        ih=img.height\n",
    "        new_shape=(self.h,self.w) #if iw>ih else (0,0,self.w,self.h)\n",
    "        if ih>iw:\n",
    "            img=TF.to_pil_image(torch.flip(TF.to_tensor(img).permute(0,2,1),(1,)))\n",
    "        return TF.resize(img,new_shape)\n",
    "\n",
    "def randint(low,high):\n",
    "    return torch.randint(low,high,(1,))[0]\n",
    "\n",
    "class CutoutTransform():\n",
    "    def __init__(self,p=0.5,size=16,fill=0.,fill_const=True):\n",
    "        self.p=p\n",
    "        self.size = (size,size) if isinstance(size,int) else size\n",
    "        if fill_const:\n",
    "            self.fill=torch.tensor([fill,fill,fill]) if isinstance(fill,(int, long, float)) else fill\n",
    "        else:\n",
    "            self.fill = None\n",
    "    def __call__(self,img):\n",
    "        if torch.rand((1,))<self.p:\n",
    "            fill = img.mean(-1).mean(-1) if self.fill is None else self.fill\n",
    "            sx=torch.randint(0,img.shape[1]-self.size[0],(1,))\n",
    "            sy=torch.randint(0,img.shape[2]-self.size[1],(1,))\n",
    "            img[:,sx:sx+self.size[0],sx:sx+self.size[0]]=fill[:,None,None]\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "class ShadeOfGrayTransform():\n",
    "    def __init__(self,power=6):\n",
    "        self.power=power\n",
    "        \n",
    "    def __call__(self,img):\n",
    "        img_power=torch.pow(img,self.power)\n",
    "        rgb_vec=torch.pow(torch.mean(img_power,(1,2)),1./self.power)\n",
    "        rgb_norm=torch.sqrt(torch.pow(rgb_vec,2.0).sum())\n",
    "        rgb_vec=rgb_vec/rgb_norm\n",
    "        return img/(np.sqrt(3)*rgb_vec[:,None,None])\n",
    "\n",
    "    \n",
    "class HairTransform():\n",
    "    def __init__(self,density):\n",
    "        self.density=int(density*300)\n",
    "        self.minx=-500\n",
    "        self.miny=-500\n",
    "        self.maxx=800\n",
    "        self.maxy=800\n",
    "        self.min_angle=0\n",
    "        self.max_angle=360\n",
    "        self.colors=[(170,136,102),(222,190,153),(36,28,17),(79,26,0),(154,51,0)]\n",
    "        self.max_width=5\n",
    "        self.color_shift=15\n",
    "    def __call__(self,img):\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        c=randint(0,len(self.colors))\n",
    "        for i in range(randint(0,self.density)):\n",
    "\n",
    "            draw.arc((randint(self.minx,self.maxx),randint(self.miny,self.maxy),\n",
    "                      randint(self.minx,self.maxx),randint(self.miny,self.maxy)), \n",
    "                     randint(self.min_angle,self.max_angle),randint(self.min_angle,self.max_angle) ,\n",
    "                     width=randint(0,self.max_width),\n",
    "                     fill=(min(max(self.colors[c][0]+randint(-self.color_shift,self.color_shift),0),255),\n",
    "                           min(max(self.colors[c][1]+randint(-self.color_shift,self.color_shift),0),255),\n",
    "                           min(max(self.colors[c][2]+randint(-self.color_shift,self.color_shift),0),255)))\n",
    "        return img\n",
    "    \n",
    "class CutMix():\n",
    "    def __init__(self,alpha):\n",
    "        self.beta=torch.distributions.beta.Beta(alpha,alpha)\n",
    "        \n",
    "    def __call__(self,images,targets):\n",
    "        n=images.shape[0]\n",
    "        _,_,w,h=images.shape\n",
    "        if n<2:\n",
    "            return images,targets\n",
    "        bt=self.beta.sample((n,))\n",
    "        b=torch.sqrt(1-bt)\n",
    "        indx=torch.randperm(n)\n",
    "        new_targets=torch.zeros_like(targets)\n",
    "        new_images=images.detach().clone()\n",
    "        rands=torch.rand((n,4))*(1-b[:,None])\n",
    "        wc=(w*b).to(torch.long)\n",
    "        hc=(h*b).to(torch.long)\n",
    "\n",
    "        for i in range(n):\n",
    "            xr=int(w*rands[i,0])\n",
    "            yr=int(h*rands[i,1])\n",
    "            xrb=int(w*rands[i,2])\n",
    "            yrb=int(h*rands[i,3])\n",
    "            new_images[i,:,xr:xr+wc[i],yr:yr+hc[i]]=images[indx[i],:,xrb:xrb+wc[i],yrb:yrb+hc[i]]\n",
    "        new_targets=(bt*targets+(1-bt)*targets[indx]) if len(targets.shape)==1 else (bt[:,None]*targets+(1-bt[:,None])*targets[indx])\n",
    "        return new_images,new_targets\n",
    "    \n",
    "class MixUp():\n",
    "    def __init__(self,alpha):\n",
    "        self.beta=torch.distributions.beta.Beta(alpha,alpha)\n",
    "        \n",
    "    def __call__(self,images,targets):\n",
    "        n=images.shape[0]\n",
    "        _,_,w,h=images.shape\n",
    "        if n<2:\n",
    "            return images,targets\n",
    "        bt=self.beta.sample((n,))\n",
    "        indx=torch.randperm(n)\n",
    "        new_targets=torch.zeros_like(targets)\n",
    "        new_images=images.detach().clone()\n",
    "        new_images=bt[:,None,None,None]*images+(1-bt[:,None,None,None])*images[indx]\n",
    "        new_targets=(bt*targets+(1-bt)*targets[indx]) if len(targets.shape)==1 else (bt[:,None]*targets+(1-bt[:,None])*targets[indx])\n",
    "        return new_images,new_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,file_path,df,transform=None,meta_aug=0,return_patient=False,return_years=False):\n",
    "        super(ImageDataset, self).__init__()\n",
    "        self.file_path=file_path\n",
    "        self.df=df\n",
    "        self.file_list=list(file_path+df.image_name+'.jpg')\n",
    "        self.sex=torch.tensor(df.sex=='male',dtype=torch.float32)\n",
    "        self.age = torch.tensor(df.age_approx,dtype=torch.float32)\n",
    "        self.anatom_site_num = torch.tensor(df.anatom_site_num,dtype=torch.long)\n",
    "        self.diagnosis = torch.tensor(df.diagnosis_num,dtype=torch.long) if 'diagnosis' in df.columns else None\n",
    "        self.target = torch.tensor(df.target,dtype=torch.long) if 'target' in df.columns else None\n",
    "        self.transform=transform\n",
    "        self.meta_aug=meta_aug\n",
    "        self.age_noise=5.\n",
    "        self.return_patient=return_patient\n",
    "        self.patient_ids=df.patient_id_num\n",
    "        self.years=None if not return_years else torch.tensor(df.years_from_min.values,dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img=self.transform(PIL.Image.open(self.file_list[idx]))\n",
    "        rands=torch.rand((3+(self.years is not None),))\n",
    "        ins = (img,)\n",
    "        if self.return_patient:\n",
    "            ins=ins+(self.patient_ids[idx],)\n",
    "        ins=ins +( self.sex[idx] if rands[0]>self.meta_aug else 1-self.sex[idx],\n",
    "                   self.age[idx]/80.0 if rands[1]>self.meta_aug else (self.age[idx]+torch.randn((1,))[0]*self.age_noise)/80.0,\n",
    "                   self.anatom_site_num[idx] if rands[2]>self.meta_aug else torch.zeros_like(self.anatom_site_num[idx]) )\n",
    "        if self.years is not None:\n",
    "            ins=ins+(torch.clamp((self.years[idx]+torch.randn((1,))[0]*(rands[3]<self.meta_aug)*self.age_noise/2)/20.0,0,10.),)\n",
    "            \n",
    "        return (*ins,self.diagnosis[idx],self.target[idx]) if self.target is not None else ins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pickle\n",
    "\n",
    "class SplitRand():\n",
    "    def __init__(self,*sums):\n",
    "        self.sums=(1,25) if len(sums)==0 else (1,sums) if len(sums)==1 else sums\n",
    "    def __call__(self,x):\n",
    "        rands=torch.randint(self.sums[0],self.sums[1],(len(x),))\n",
    "        i=1\n",
    "        while rands[:i].sum()<len(x):\n",
    "            i=i+1\n",
    "        return [x[rands[:j].sum():rands[:j+1].sum()] for j in range(i)]\n",
    "\n",
    "class PatientFeaturesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,features,df,patients,max_len,meta_aug=0,const_f=None,rep=1,sort_age=False,min_len=None):\n",
    "        super(PatientFeaturesDataset, self).__init__()\n",
    "        self.df=df\n",
    "        self.sort_age=sort_age\n",
    "        self.features=features if isinstance(features,list) else [features]\n",
    "        self.const_f=const_f if const_f is None else [const_f]*max_len\n",
    "        self.max_len=max_len\n",
    "        self.subset = df.patient_id.isin(patients).values\n",
    "        self.sex=torch.zeros(self.features[0].shape[1],dtype=torch.long)\n",
    "        self.age = torch.zeros(self.features[0].shape[1],dtype=torch.float32)\n",
    "        self.anatom_site_num = torch.zeros(self.features[0].shape[1],dtype=torch.long)\n",
    "        self.years=torch.zeros(self.features[0].shape[1],dtype=torch.float32)\n",
    "        self.mask=torch.ones(self.features[0].shape[1],dtype=torch.float32)\n",
    "        self.mask[-1]=0\n",
    "        self.sex[:-1]=torch.tensor(df.sex=='male',dtype=torch.float32)\n",
    "        self.age[:-1] = torch.tensor(df.age_approx,dtype=torch.float32)\n",
    "        self.anatom_site_num[:-1] = torch.tensor(df.anatom_site_num,dtype=torch.long)\n",
    "        self.years[:-1]=torch.tensor(df.years_from_min.values,dtype=torch.float32)\n",
    "        self.split_rand=None if min_len is None else SplitRand(min_len,max_len)\n",
    "        self.rep=rep\n",
    "        self.reset()\n",
    "        if 'diagnosis' in df.columns:\n",
    "            self.diagnosis = -torch.ones(self.features[0].shape[1],dtype=torch.long)\n",
    "            self.target = -torch.ones(self.features[0].shape[1],dtype=torch.long)\n",
    "            self.diagnosis[:-1]=torch.tensor(df.diagnosis_num,dtype=torch.long)\n",
    "            self.target[:-1] = torch.tensor(df.target,dtype=torch.long) \n",
    "        else:\n",
    "            self.diagnosis=None\n",
    "            self.target=None\n",
    "        \n",
    "\n",
    "        \n",
    "    def reset(self):\n",
    "\n",
    "        gp=self.df[self.subset].groupby('patient_id')\n",
    "        idx_list=[]\n",
    "        num_ids_list=[]\n",
    "        for j in range(self.rep):\n",
    "            for g in gp.groups.items():\n",
    "                idxs=g[1].values\n",
    "                np.random.shuffle(idxs)\n",
    "                if self.split_rand is None:\n",
    "                    n=int(np.ceil(len(idxs)/self.max_len))\n",
    "                    t = len(idxs)//n\n",
    "                    tp = len(idxs)%n\n",
    "                    k0=0\n",
    "                    for i in range(n):\n",
    "                        idx_list.append(np.ones((self.max_len,),dtype=int)*self.features[0].shape[1]-1)\n",
    "                        k1=k0+t +(tp>i)\n",
    "                        ni = idxs[k0:k1]\n",
    "                        num_ids_list.append(len(ni))\n",
    "                        if self.sort_age:\n",
    "                            ni=ni[np.argsort(-self.age[ni])]\n",
    "                        idx_list[-1][:len(idxs[k0:k1])]=ni\n",
    "                        k0=k1 \n",
    "                else:\n",
    "                    new_groups=self.split_rand(idxs)\n",
    "                    for grp in new_groups:\n",
    "                        idx_list.append(np.ones((self.max_len,),dtype=int)*self.features[0].shape[1]-1)\n",
    "                        idx_list[-1][:len(grp)]=grp\n",
    "        self.idx_array=np.stack(idx_list)       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_array*self.rep)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        a= torch.randint(0,self.features[0].shape[0],(len(self.features),self.max_len,)) if self.const_f is None else self.const_f\n",
    "        rt=(torch.cat([self.features[i][a[i],self.idx_array[idx]]  for i in range(len(self.features))],-1),\n",
    "            self.sex[self.idx_array[idx]],\n",
    "            self.age[self.idx_array[idx]],\n",
    "            self.anatom_site_num[self.idx_array[idx]],\n",
    "            self.years[self.idx_array[idx]],\n",
    "            self.mask[self.idx_array[idx]],\n",
    "            torch.tensor(self.idx_array[idx],dtype=torch.long))\n",
    "        if self.target is not None:\n",
    "            rt = rt + (self.diagnosis[self.idx_array[idx]],self.target[self.idx_array[idx]])\n",
    "        return rt\n",
    "\n",
    "\n",
    "class TransformerBatchSampler():\n",
    "    def __init__(self,ds,max_indx_in_batch=24,shuffle=True):\n",
    "        self.shuffle=shuffle\n",
    "        self.ds=ds \n",
    "        self.max_indx_in_batch=max_indx_in_batch\n",
    "        self.reset()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.batchs)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.batchs:\n",
    "            yield batch\n",
    "        \n",
    "    def reset(self):\n",
    "        self.indx_list=self.ds.idx_list\n",
    "        self.lengths=np.array([len(i) for i in self.indx_list])\n",
    "        self.indx_list=self.indx_list if not self.shuffle else [self.indx_list[i] for i in torch.randperm(len(self.indx_list))]\n",
    "        self.batchs=[]\n",
    "        for l in np.unique(self.lengths):\n",
    "            n = np.where(self.lengths==l)[0]\n",
    "            k = self.max_indx_in_batch//l\n",
    "            if len(n)//k>0:\n",
    "                self.batchs.extend(n[:k*(len(n)//k)].reshape(-1,k).tolist())\n",
    "            if len(n)%k>0:\n",
    "                self.batchs.append(n[k*(len(n)//k):].tolist())\n",
    "        if self.shuffle:\n",
    "            self.batchs=[self.batchs[i] for i in torch.randperm(len(self.batchs))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted ProcessData.ipynb to exp/ProcessData.py\r\n"
     ]
    }
   ],
   "source": [
    "full_notebook_name=theNotebook+'.ipynb'\n",
    "!python notebook2script.py {full_notebook_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
