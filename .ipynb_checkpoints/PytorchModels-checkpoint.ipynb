{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from exp.misc import *\n",
    "#from exp.ProcessData import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import pretrainedmodels\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "class Noop(nn.Module):\n",
    "    def __init__(self,*args):\n",
    "        super(Noop, self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x\n",
    "\n",
    "class NoopAddDim(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NoopAddDim, self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.unsqueeze(-1)\n",
    "\n",
    "def add_to_dim(x,num_dims,dim=0):\n",
    "    while len(x.shape)<num_dims:\n",
    "        x=x.unsqueeze(dim)\n",
    "    return x\n",
    "\n",
    "class DummyEmbd(nn.Module):\n",
    "    def __init__(self,out_size,dtype=torch.float32):\n",
    "        super(DummyEmbd, self).__init__()\n",
    "        self.out_size=out_size\n",
    "        self.dtype=dtype\n",
    "    def forward(self,x):\n",
    "        return torch.zeros(x.shape+(self.out_size,),dtype=self.dtype,device=x.device)\n",
    "\n",
    "def soft_cross_entropy (input, target):\n",
    "    return  -(target * F.log_softmax (input, dim = 1)).sum(1).mean(0)\n",
    "\n",
    "class FocalCrossEntropy():\n",
    "    def __init__(self,gamma):\n",
    "        self.gamma=gamma\n",
    "        \n",
    "    def __call__(self,pred,target):\n",
    "        if pred.shape!=target.shape:\n",
    "            targets = torch.zeros_like(pred)\n",
    "            targets[torch.arange(target.shape[0]),target]=1\n",
    "        else:\n",
    "            targets=target\n",
    "        return -(torch.pow(1-F.softmax(pred, dim = 1),self.gamma) * targets * F.log_softmax (pred, dim = 1)).sum(1).mean(0) \n",
    "    \n",
    "class ExtraModel(nn.Module):\n",
    "    def __init__(self,model,last_layer,extras,mid_linear,mlps=[],extra_activation=nn.ReLU(),dropout=0,bn=False,\n",
    "                 patient_emdb=None,return_features=False):\n",
    "        super(ExtraModel, self).__init__()\n",
    "        self.base_model=copy.deepcopy(model)\n",
    "        self.return_features=return_features\n",
    "        last = self.base_model._modules[last_layer]\n",
    "        in_last=last.in_features\n",
    "        out_last=last.out_features\n",
    "        bias_last=last.bias\n",
    "        added_ins=0\n",
    "        for i,l in enumerate(extras):\n",
    "            if isinstance(l,(list,tuple)) and len(l)==2:\n",
    "                self.add_module(f'extra_layers{i}',nn.Embedding(l[0], l[1]))\n",
    "                added_ins+=l[1]\n",
    "            elif isinstance(l,int):\n",
    "                if l>1:\n",
    "                    self.add_module(f'extra_layers{i}',nn.Sequential(NoopAddDim(),nn.Linear(1, l)))\n",
    "                    added_ins+=l\n",
    "                else:\n",
    "                    self.add_module(f'extra_layers{i}',NoopAddDim())\n",
    "                    added_ins+=1\n",
    "            else:\n",
    "                raise ValueError(f'extras {i} is {l} which is not an interger or a list/tuple of size 2')                \n",
    "        self.extra_linear=nn.Linear(added_ins,mid_linear)\n",
    "        self.extra_bn=nn.BatchNorm1d(mid_linear) if bn else Noop()\n",
    "        self.extra_dropout = nn.Dropout(dropout) if dropout>0 else Noop()\n",
    "        self.patient_embd=patient_emdb if patient_emdb is None else nn.Embedding.from_pretrained(patient_emdb)\n",
    "        em_size=0 if self.patient_embd is None else patient_emdb.shape[1]\n",
    "        if len(mlps)==0:\n",
    "            self.last_linear=nn.Linear(mid_linear+in_last+em_size,out_last,bias=bias_last is not None)\n",
    "        else:\n",
    "            nmlps=[mid_linear+in_last+em_size]+mlps\n",
    "            sq = [x for s in [[nn.Linear(nmlps[i],nmlps[i+1]),\n",
    "                               extra_activation,\n",
    "                               nn.BatchNorm1d(nmlps[i+1]) if bn else Noop(),\n",
    "                               nn.Dropout(dropout) if dropout>0 else Noop()] for i in range(len(mlps))] for x in s]\n",
    "            self.add_module('mlps',nn.Sequential(*tuple(sq)))\n",
    "            self.last_linear=nn.Linear(mlps[-1],out_last,bias=bias_last is not None)\n",
    "        self.extra_activation=extra_activation\n",
    "        self.base_model._modules[last_layer]=Noop()\n",
    "\n",
    "\n",
    "    def forward(self,x,*extra):\n",
    "        x = self.base_model(x)\n",
    "        if self.patient_embd is not None:\n",
    "            x=torch.cat([x,self.patient_embd(extra[0])],1)\n",
    "            extra=extra[1:]\n",
    "        extra=torch.cat([self.extra_activation(getattr(self,f'extra_layers{i}')(extra[i])) for i in range(len(extra))],1)\n",
    "        extra=self.extra_activation(self.extra_linear(extra))\n",
    "        x=torch.cat([x,extra],1)\n",
    "        if hasattr(self,'mlps'):\n",
    "            x=self.mlps(x)\n",
    "        out = self.last_linear(x)\n",
    "        return (out,x) if self.return_features else out\n",
    "        \n",
    "import math\n",
    "def calc_positional_encoder(d_model, max_seq_len = 32):       \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        return pe/(d_model**0.5) \n",
    "    \n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self,in_size,\n",
    "                 dim_feedforward,\n",
    "                 n_heads=4,\n",
    "                 n_encoders=4,\n",
    "                 num_outputs=8,\n",
    "                 use_age=True,\n",
    "                 max_site_num=7,\n",
    "                 use_sex=True,\n",
    "                 use_age_diff=True,\n",
    "                 use_position_enc=False):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.in_size=in_size\n",
    "        self.encoder_layer =nn.TransformerEncoderLayer(in_size, \n",
    "                                                       n_heads, \n",
    "                                                       dim_feedforward=dim_feedforward)\n",
    "#        self.decoder_layer =nn.TransformerDecoderLayer(in_size, 4, dim_feedforward=in_size)\n",
    "        self.encoder=nn.TransformerEncoder(self.encoder_layer, n_encoders)\n",
    "#        self.decoder=nn.TransformerDecoder(self.decoder_layer, 2)\n",
    "        self.sex_embd=nn.Embedding(2,in_size) if  use_sex else DummyEmbd(in_size)\n",
    "        self.age_embd=nn.Sequential(NoopAddDim(),nn.Linear(1,16),nn.ReLU(),nn.Linear(16,in_size)) if use_age else DummyEmbd(in_size)\n",
    "        self.site_embd=nn.Embedding(max_site_num,in_size) if max_site_num>0 else DummyEmbd(in_size)\n",
    "        self.age_diff_embd=nn.Sequential(NoopAddDim(),nn.Linear(1,16),nn.ReLU(),nn.Linear(16,in_size)) if use_age else DummyEmbd(in_size)\n",
    "        self.classifier = nn.Linear(in_size, num_outputs)\n",
    "        self.pos_embd=calc_positional_encoder(in_size) if use_position_enc else None\n",
    "\n",
    "    def forward(self, x,sex=None,age=None,site=None,age_diff=None,mask=None):\n",
    "        if self.pos_embd is not None:\n",
    "            if self.pos_embd.device!=x.device:\n",
    "                self.pos_embd = self.pos_embd.to(x.device)  \n",
    "        x = x if sex is None else x + self.sex_embd(sex)\n",
    "        x = x if age is None else x + self.age_embd(age)\n",
    "        x = x if site is None else x + self.site_embd(site)\n",
    "        x = x if age_diff is None else x + self.age_diff_embd(age_diff)\n",
    "        x = x if self.pos_embd is None else x + self.pos_embd[:x.shape[1]][None]\n",
    "        x = x if mask is None else x*mask.unsqueeze(-1)\n",
    "        x = self.encoder(x.permute(1,0,-1)) #,mask=s_mask\n",
    "        x = x.permute(1,0,-1)\n",
    "        out = self.classifier(x)\n",
    "        return out   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import pretrainedmodels\n",
    "import geffnet\n",
    "def get_model(model_name,output_size,pretrained=True, extra=None, mid_extra=0,extra_activation=nn.ReLU(),\n",
    "              mlps=[],dropout=0,bn=False,patient_emdb=None,return_features=False):\n",
    "    if model_name.startswith('resne'):\n",
    "        m=getattr(models,model_name)\n",
    "        model=m(pretrained=pretrained)\n",
    "        model.fc=nn.Linear(model.fc.in_features,output_size)\n",
    "        last = 'fc'\n",
    "    elif model_name.startswith('densenet'):\n",
    "        m=getattr(models,model_name)\n",
    "        model=m(pretrained=pretrained)\n",
    "        model.classifier=nn.Linear(model.classifier.in_features,output_size)\n",
    "        last='classifier'\n",
    "    elif model_name.startswith('my_densenet'):\n",
    "        model=models.DenseNet(32,block_config=(6, 12,32),num_init_features=64,num_classes=output_size)\n",
    "    elif model_name in ['efficientnet_b0','efficientnet_b1','efficientnet_b2','efficientnet_b3'] or model_name.startswith('tf_'):\n",
    "        model=geffnet.create_model( model_name, pretrained=pretrained)\n",
    "        model.classifier=nn.Linear(model.classifier.in_features,output_size)\n",
    "        last = 'classifier'\n",
    "    elif model_name=='DCTConvModel':\n",
    "        model=DCTConvModel()\n",
    "    elif model_name=='xception':\n",
    "        model=pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "        model.last_linear=nn.Linear(model.last_linear.in_features,output_size)\n",
    "        last='last_linear'\n",
    "\n",
    "    else:\n",
    "        raise ValueError('no model named '+model_name)\n",
    "    if extra is not None and mid_extra>0:\n",
    "        model= ExtraModel(model,last,extra,mid_linear=mid_extra,extra_activation=extra_activation,\n",
    "                          mlps=mlps,dropout=dropout,bn=bn,patient_emdb=patient_emdb,return_features=return_features)\n",
    "    elif len(mlps)>0:\n",
    "        in_last=model._modules[last].in_features\n",
    "        out_last=model._modules[last].out_features\n",
    "        nmlps=[in_last]+mlps\n",
    "        sq = OrderedDict([x for s in [[(f'mlp_linear{i}',nn.Linear(nmlps[i],nmlps[i+1])),\n",
    "                           (f'mlp_act{i}',extra_activation),\n",
    "                           (f'mlp_bn{i}',nn.BatchNorm1d(nmlps[i+1]) if bn else Noop()),\n",
    "                           (f'mlp_dropout{i}',nn.Dropout(dropout) if dropout>0 else Noop())] for i in range(len(mlps))] for x in s])\n",
    "        sq['last_linear'] = nn.Linear(nmlps[-1],out_last)\n",
    "        model._modules[last]=nn.Sequential(sq)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=get_model('efficientnet_b0',5,mlps=[1024,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenEfficientNet(\n",
       "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): SwishJit()\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SwishJit()\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SwishJit()\n",
       "        (se): SqueezeExcite(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SwishJit()\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): SwishJit()\n",
       "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (mlp_linear0): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "    (mlp_act0): ReLU()\n",
       "    (mlp_bn0): Noop()\n",
       "    (mlp_dropout0): Noop()\n",
       "    (mlp_linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (mlp_act1): ReLU()\n",
       "    (mlp_bn1): Noop()\n",
       "    (mlp_dropout1): Noop()\n",
       "    (last_linear): Linear(in_features=256, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted PytorchModels.ipynb to exp/PytorchModels.py\r\n"
     ]
    }
   ],
   "source": [
    "full_notebook_name=theNotebook+'.ipynb'\n",
    "!python notebook2script.py {full_notebook_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
