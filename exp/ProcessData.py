
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/ProcessData.ipynb

import pandas as pd
import numpy as np
from tqdm import notebook
from exp.misc import *
import torch
import PIL.Image
import pydicom
import cv2
from torchvision import transforms
import torchvision.transforms.functional as TF
from collections import defaultdict

from torch.utils.data import Dataset
class DatasetCat(Dataset):
    '''
    Concatenate datasets for Pytorch dataloader
    The normal pytorch implementation does it only for raws. this is a "column" implementation
    Arges:
        datasets: list of datasets, of the same length
    Updated: Yuval 12/10/2019
    '''

    def __init__(self,datasets):
        '''
        Args: datasets - an iterable containing the datasets
        '''
        super(DatasetCat, self).__init__()
        self.datasets=datasets
        assert len(self.datasets)>0
        for dataset in datasets:
            assert len(self.datasets[0])==len(dataset),"Datasets length should be equal"

    def __len__(self):
        return len(self.datasets[0])

    def __getitem__(self, idx):
        outputs = tuple(dataset.__getitem__(idx) for i in self.datasets for dataset in (i if isinstance(i, tuple) else (i,)))
        return tuple(output for i in outputs for output in (i if isinstance(i, tuple) else (i,)))


def prepare_df(df):
    df.sex=df.sex.fillna('male')
    if 'SOPInstanceUID_grp' in df.columns:
        df.SOPInstanceUID_grp=df.SOPInstanceUID_grp.fillna(0)
    if 'patient_id_cnt_enc' in df.columns:
        df.patient_id_cnt_enc=df.patient_id_cnt_enc.fillna(2)
    df.age_approx=df.age_approx.fillna(45.0)
    if 'diagnosis' in df.columns:
        diagnosis_dict=defaultdict(lambda :0,[('melanoma',1),('nevus',2),('seborrheic keratosis',3),
                                              ("Basal cell carcinoma",4),("Actinic keratosis",3),("Benign keratosis",3),
                                             ("Dermatofibroma",5),("Vascular lesion",6),("Squamous cell carcinoma",7)])
        df['diagnosis_num']=df.diagnosis.map(diagnosis_dict)
        has_target=df.groupby(by='patient_id')['target'].max().rename('patient_melanoma').reset_index()
        df['patient_melanoma']=df.merge(has_target,on='patient_id',how='left')['patient_melanoma']
    anatom_site_dict=defaultdict(lambda :0,[('head/neck',1), ('upper extremity',2), ('lower extremity',3), ('torso',4),
           ('palms/soles',5), ('oral/genital',6),('anterior torso',4),('posterior torso',4),('posterior torso',4)])
    df['anatom_site_num']=df['anatom_site_general_challenge'].map(anatom_site_dict)
    df.patient_id=df.patient_id.fillna('0')
    patient_ids=df.patient_id.unique()
    patient_ids.sort()
    df['patient_id_num']=df.patient_id.map(dict(zip(patient_ids,range(len(patient_ids)))))
    gp=df[['patient_id','age_approx']].groupby('patient_id')['age_approx'].min().rename('min_age').reset_index()
    df['min_age']=df.merge(gp,on='patient_id',how='left')['min_age']
    df['years_from_min']=df['age_approx']-df['min_age']
    df.years_from_min=df.years_from_min*(df.patient_id!='0')

def creat_folds(train_df,num_folds,SEED):
    upatient_0=np.sort(train_df[train_df.patient_melanoma==0].patient_id.unique())
    upatient_1=np.sort(train_df[train_df.patient_melanoma==1].patient_id.unique())
    np.random.seed(SEED)
    np.random.shuffle(upatient_0)
    np.random.seed(SEED)
    np.random.shuffle(upatient_1)
    nu0=int(np.ceil(upatient_0.shape[0]/num_folds))
    nu1=int(np.ceil(upatient_1.shape[0]/num_folds))
    patients_val=[set(np.concatenate([upatient_0[i*nu0:(i+1)*nu0],upatient_1[i*nu1:(i+1)*nu1]])) for i in range(num_folds)]
    val_folds=[np.sort(np.where(train_df.patient_id.isin(patients_val[i]))[0]) for i in range(num_folds)]
    train_folds=[np.sort(np.setdiff1d(np.arange(train_df.shape[0]),val_folds[i])) for i in range(num_folds)]
    return val_folds, train_folds, patients_val

def create_folds_extra(train_df,num_folds,SEED):
    upatient_0=np.sort(train_df[(train_df.patient_melanoma==0) & (train_df.patient_id!='0')].patient_id.unique())
    upatient_1=np.sort(train_df[(train_df.patient_melanoma==1) & (train_df.patient_id!='0')].patient_id.unique())
    np.random.seed(SEED)
    np.random.shuffle(upatient_0)
    np.random.seed(SEED)
    np.random.shuffle(upatient_1)

    nu0=int(np.ceil(upatient_0.shape[0]/num_folds))
    nu1=int(np.ceil(upatient_1.shape[0]/num_folds))
    patients_val=[set(np.concatenate([upatient_0[i*nu0:(i+1)*nu0],upatient_1[i*nu1:(i+1)*nu1]])) for i in range(num_folds)]
    nan_val=np.sort(np.where(train_df.patient_id=='0')[0])
    np.random.seed(SEED)
    nan0=int(np.ceil(nan_val.shape[0]/num_folds))
    np.random.shuffle(nan_val)
    nan_folds=[nan_val[i*nan0:(i+1)*nan0] for i in range(num_folds)]
    val_folds=[np.concatenate([nan_folds[i],np.sort(np.where(train_df.patient_id.isin(patients_val[i]))[0])]) for i in range(num_folds)]
    train_folds=[np.sort(np.setdiff1d(np.arange(train_df.shape[0]),val_folds[i])) for i in range(num_folds)]
    return val_folds, train_folds, patients_val


def calc_enbd_mat(df,features,norm=False,do_max=False,rand_rows=0):
    rand_rows=rand_rows if rand_rows>0 else features.shape[0]
    features=features if not norm else features/np.linalg.norm(features,  axis=-1, keepdims=True)
    gp=df[['image_name','patient_id_num']].groupby('patient_id_num')
    embd_mat_mean=torch.zeros((len(gp),features.shape[-1]),dtype=torch.float32)
    embd_mat_meanmax=torch.zeros((len(gp),features.shape[-1]),dtype=torch.float32)
    embd_mat_maxmean=torch.zeros((len(gp),features.shape[-1]),dtype=torch.float32)
    for i,g in enumerate(gp.groups.items()):
        idx = g[1].values
        b=np.stack([np.random.choice(features.shape[0],rand_rows,replace=False) for i in range(len(idx))])
        a=idx.repeat(rand_rows).reshape(-1,rand_rows)
        if (idx<features.shape[1]).all():
            embd_mat_mean[i]=torch.tensor(features[b,a,:].mean(0).mean(0),dtype=torch.float32)
            if do_max:
                embd_mat_maxmean[i]=torch.tensor(features[b,a,:].mean(1).max(0),dtype=torch.float32)
                embd_mat_meanmax[i]=torch.tensor(features[b,a,:].mean(0).max(0),dtype=torch.float32)

    return  torch.cat([embd_mat_mean,embd_mat_maxmean,embd_mat_meanmax],-1) if do_max else embd_mat_mean

from PIL import  ImageDraw
import torch

class MyResize():
    def __init__(self,h,w):
        (self.h,self.w) = (h,w) if w>h else (w,h)
    def __call__(self,img):
        iw=img.width
        ih=img.height
        k1=max(iw,ih)/self.w
        k2=min(iw,ih)/self.h
        new_shape=(0,0,self.h,self.w) #if iw>ih else (0,0,self.w,self.h)
        if ih>iw:
            img=TF.to_pil_image(torch.flip(TF.to_tensor(img).permute(0,2,1),(1,)))
        return TF.crop(TF.resize(img,int(min(iw,ih)/max(k1,k2))),*new_shape)

class MyResize2():
    def __init__(self,h,w):
        (self.h,self.w) = (h,w) if w>h else (w,h)
    def __call__(self,img):
        iw=img.width
        ih=img.height
        new_shape=(self.h,self.w) #if iw>ih else (0,0,self.w,self.h)
        if ih>iw:
            img=TF.to_pil_image(torch.flip(TF.to_tensor(img).permute(0,2,1),(1,)))
        return TF.resize(img,new_shape)

def randint(low,high):
    return torch.randint(low,high,(1,))[0]

class CutoutTransform():
    def __init__(self,p=0.5,size=16,fill=0.,fill_const=True):
        self.p=p
        self.size = (size,size) if isinstance(size,int) else size
        if fill_const:
            self.fill=torch.tensor([fill,fill,fill]) if isinstance(fill,(int, long, float)) else fill
        else:
            self.fill = None
    def __call__(self,img):
        if torch.rand((1,))<self.p:
            fill = img.mean(-1).mean(-1) if self.fill is None else self.fill
            sx=torch.randint(0,img.shape[1]-self.size[0],(1,))
            sy=torch.randint(0,img.shape[2]-self.size[1],(1,))
            img[:,sx:sx+self.size[0],sx:sx+self.size[0]]=fill[:,None,None]
        return img



class ShadeOfGrayTransform():
    def __init__(self,power=6):
        self.power=power

    def __call__(self,img):
        img_power=torch.pow(img,self.power)
        rgb_vec=torch.pow(torch.mean(img_power,(1,2)),1./self.power)
        rgb_norm=torch.sqrt(torch.pow(rgb_vec,2.0).sum())
        rgb_vec=rgb_vec/rgb_norm
        return img/(np.sqrt(3)*rgb_vec[:,None,None])


class HairTransform():
    def __init__(self,density):
        self.density=int(density*300)
        self.minx=-500
        self.miny=-500
        self.maxx=800
        self.maxy=800
        self.min_angle=0
        self.max_angle=360
        self.colors=[(170,136,102),(222,190,153),(36,28,17),(79,26,0),(154,51,0)]
        self.max_width=5
        self.color_shift=15
    def __call__(self,img):
        draw = ImageDraw.Draw(img)
        c=randint(0,len(self.colors))
        for i in range(randint(0,self.density)):

            draw.arc((randint(self.minx,self.maxx),randint(self.miny,self.maxy),
                      randint(self.minx,self.maxx),randint(self.miny,self.maxy)),
                     randint(self.min_angle,self.max_angle),randint(self.min_angle,self.max_angle) ,
                     width=randint(0,self.max_width),
                     fill=(min(max(self.colors[c][0]+randint(-self.color_shift,self.color_shift),0),255),
                           min(max(self.colors[c][1]+randint(-self.color_shift,self.color_shift),0),255),
                           min(max(self.colors[c][2]+randint(-self.color_shift,self.color_shift),0),255)))
        return img

class CutMix():
    def __init__(self,alpha):
        self.beta=torch.distributions.beta.Beta(alpha,alpha)

    def __call__(self,images,targets):
        n=images.shape[0]
        _,_,w,h=images.shape
        if n<2:
            return images,targets
        bt=self.beta.sample((n,))
        b=torch.sqrt(1-bt)
        indx=torch.randperm(n)
        new_targets=torch.zeros_like(targets)
        new_images=images.detach().clone()
        rands=torch.rand((n,4))*(1-b[:,None])
        wc=(w*b).to(torch.long)
        hc=(h*b).to(torch.long)

        for i in range(n):
            xr=int(w*rands[i,0])
            yr=int(h*rands[i,1])
            xrb=int(w*rands[i,2])
            yrb=int(h*rands[i,3])
            new_images[i,:,xr:xr+wc[i],yr:yr+hc[i]]=images[indx[i],:,xrb:xrb+wc[i],yrb:yrb+hc[i]]
        new_targets=(bt*targets+(1-bt)*targets[indx]) if len(targets.shape)==1 else (bt[:,None]*targets+(1-bt[:,None])*targets[indx])
        return new_images,new_targets

class MixUp():
    def __init__(self,alpha):
        self.beta=torch.distributions.beta.Beta(alpha,alpha)

    def __call__(self,images,targets):
        n=images.shape[0]
        _,_,w,h=images.shape
        if n<2:
            return images,targets
        bt=self.beta.sample((n,))
        indx=torch.randperm(n)
        new_targets=torch.zeros_like(targets)
        new_images=images.detach().clone()
        new_images=bt[:,None,None,None]*images+(1-bt[:,None,None,None])*images[indx]
        new_targets=(bt*targets+(1-bt)*targets[indx]) if len(targets.shape)==1 else (bt[:,None]*targets+(1-bt[:,None])*targets[indx])
        return new_images,new_targets

class ImageDataset(Dataset):

    def __init__(self,file_path,df,transform=None,meta_aug=0,return_patient=False,return_years=False):
        super(ImageDataset, self).__init__()
        self.file_path=file_path
        self.df=df
        self.file_list=list(file_path+df.image_name+'.jpg')
        self.sex=torch.tensor(df.sex=='male',dtype=torch.float32)
        self.age = torch.tensor(df.age_approx,dtype=torch.float32)
        self.anatom_site_num = torch.tensor(df.anatom_site_num,dtype=torch.long)
        self.diagnosis = torch.tensor(df.diagnosis_num,dtype=torch.long) if 'diagnosis' in df.columns else None
        self.target = torch.tensor(df.target,dtype=torch.long) if 'target' in df.columns else None
        self.transform=transform
        self.meta_aug=meta_aug
        self.age_noise=5.
        self.return_patient=return_patient
        self.patient_ids=df.patient_id_num
        self.years=None if not return_years else torch.tensor(df.years_from_min.values,dtype=torch.float32)

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self,idx):
        img=self.transform(PIL.Image.open(self.file_list[idx]))
        rands=torch.rand((3+(self.years is not None),))
        ins = (img,)
        if self.return_patient:
            ins=ins+(self.patient_ids[idx],)
        ins=ins +( self.sex[idx] if rands[0]>self.meta_aug else 1-self.sex[idx],
                   self.age[idx]/80.0 if rands[1]>self.meta_aug else (self.age[idx]+torch.randn((1,))[0]*self.age_noise)/80.0,
                   self.anatom_site_num[idx] if rands[2]>self.meta_aug else torch.zeros_like(self.anatom_site_num[idx]) )
        if self.years is not None:
            ins=ins+(torch.clamp((self.years[idx]+torch.randn((1,))[0]*(rands[3]<self.meta_aug)*self.age_noise/2)/20.0,0,10.),)

        return (*ins,self.diagnosis[idx],self.target[idx]) if self.target is not None else ins



import pickle

class SplitRand():
    def __init__(self,*sums):
        self.sums=(1,25) if len(sums)==0 else (1,sums) if len(sums)==1 else sums
    def __call__(self,x):
        rands=torch.randint(self.sums[0],self.sums[1],(len(x),))
        i=1
        while rands[:i].sum()<len(x):
            i=i+1
        return [x[rands[:j].sum():rands[:j+1].sum()] for j in range(i)]

class PatientFeaturesDataset(Dataset):

    def __init__(self,features,df,patients,max_len,meta_aug=0,const_f=None,rep=1,sort_age=False,min_len=None):
        super(PatientFeaturesDataset, self).__init__()
        self.df=df
        self.sort_age=sort_age
        self.features=features if isinstance(features,list) else [features]
        self.const_f=const_f if const_f is None else [const_f]*max_len
        self.max_len=max_len
        self.subset = df.patient_id.isin(patients).values
        self.sex=torch.zeros(self.features[0].shape[1],dtype=torch.long)
        self.age = torch.zeros(self.features[0].shape[1],dtype=torch.float32)
        self.anatom_site_num = torch.zeros(self.features[0].shape[1],dtype=torch.long)
        self.years=torch.zeros(self.features[0].shape[1],dtype=torch.float32)
        self.mask=torch.ones(self.features[0].shape[1],dtype=torch.float32)
        self.mask[-1]=0
        self.sex[:-1]=torch.tensor(df.sex=='male',dtype=torch.float32)
        self.age[:-1] = torch.tensor(df.age_approx,dtype=torch.float32)
        self.anatom_site_num[:-1] = torch.tensor(df.anatom_site_num,dtype=torch.long)
        self.years[:-1]=torch.tensor(df.years_from_min.values,dtype=torch.float32)
        self.split_rand=None if min_len is None else SplitRand(min_len,max_len)
        self.rep=rep
        self.reset()
        if 'diagnosis' in df.columns:
            self.diagnosis = -torch.ones(self.features[0].shape[1],dtype=torch.long)
            self.target = -torch.ones(self.features[0].shape[1],dtype=torch.long)
            self.diagnosis[:-1]=torch.tensor(df.diagnosis_num,dtype=torch.long)
            self.target[:-1] = torch.tensor(df.target,dtype=torch.long)
        else:
            self.diagnosis=None
            self.target=None



    def reset(self):

        gp=self.df[self.subset].groupby('patient_id')
        idx_list=[]
        num_ids_list=[]
        for j in range(self.rep):
            for g in gp.groups.items():
                idxs=g[1].values
                np.random.shuffle(idxs)
                if self.split_rand is None:
                    n=int(np.ceil(len(idxs)/self.max_len))
                    t = len(idxs)//n
                    tp = len(idxs)%n
                    k0=0
                    for i in range(n):
                        idx_list.append(np.ones((self.max_len,),dtype=int)*self.features[0].shape[1]-1)
                        k1=k0+t +(tp>i)
                        ni = idxs[k0:k1]
                        num_ids_list.append(len(ni))
                        if self.sort_age:
                            ni=ni[np.argsort(-self.age[ni])]
                        idx_list[-1][:len(idxs[k0:k1])]=ni
                        k0=k1
                else:
                    new_groups=self.split_rand(idxs)
                    for grp in new_groups:
                        idx_list.append(np.ones((self.max_len,),dtype=int)*self.features[0].shape[1]-1)
                        idx_list[-1][:len(grp)]=grp
        self.idx_array=np.stack(idx_list)

    def __len__(self):
        return len(self.idx_array*self.rep)

    def __getitem__(self,idx):
        a= torch.randint(0,self.features[0].shape[0],(len(self.features),self.max_len,)) if self.const_f is None else self.const_f
        rt=(torch.cat([self.features[i][a[i],self.idx_array[idx]]  for i in range(len(self.features))],-1),
            self.sex[self.idx_array[idx]],
            self.age[self.idx_array[idx]],
            self.anatom_site_num[self.idx_array[idx]],
            self.years[self.idx_array[idx]],
            self.mask[self.idx_array[idx]],
            torch.tensor(self.idx_array[idx],dtype=torch.long))
        if self.target is not None:
            rt = rt + (self.diagnosis[self.idx_array[idx]],self.target[self.idx_array[idx]])
        return rt


class TransformerBatchSampler():
    def __init__(self,ds,max_indx_in_batch=24,shuffle=True):
        self.shuffle=shuffle
        self.ds=ds
        self.max_indx_in_batch=max_indx_in_batch
        self.reset()

    def __len__(self):
        return len(self.batchs)

    def __iter__(self):
        for batch in self.batchs:
            yield batch

    def reset(self):
        self.indx_list=self.ds.idx_list
        self.lengths=np.array([len(i) for i in self.indx_list])
        self.indx_list=self.indx_list if not self.shuffle else [self.indx_list[i] for i in torch.randperm(len(self.indx_list))]
        self.batchs=[]
        for l in np.unique(self.lengths):
            n = np.where(self.lengths==l)[0]
            k = self.max_indx_in_batch//l
            if len(n)//k>0:
                self.batchs.extend(n[:k*(len(n)//k)].reshape(-1,k).tolist())
            if len(n)%k>0:
                self.batchs.append(n[k*(len(n)//k):].tolist())
        if self.shuffle:
            self.batchs=[self.batchs[i] for i in torch.randperm(len(self.batchs))]
