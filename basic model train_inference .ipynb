{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from exp.misc import *\n",
    "from exp.ProcessData import *\n",
    "from exp.PytorchModels import *\n",
    "from exp.LearnerClass import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from torchvision import transforms\n",
    "import PIL.Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torchvision.transforms.functional as TF\n",
    "from types import MethodType\n",
    "import sandesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=json_to_parameters('config.json')\n",
    "num_folds=3\n",
    "SEEDS=[220,432,8153]\n",
    "add_seed=214456\n",
    "model_type='tf_efficientnet_b5_ns'\n",
    "name_tamplate='image_mlps_cut_128_seed_fullv{}'\n",
    "output_name=f'{model_type}_image_mlps_cut_128_seed_fullv_predict.pth'\n",
    "\n",
    "device = device_by_name('Tesla')\n",
    "\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(params.path.data+'train.csv')\n",
    "extra_df=pd.read_csv(params.path.data+'isim2019.csv')\n",
    "train_df=pd.concat([train_df, extra_df], ignore_index=True,sort=False)\n",
    "prepare_df(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metric(y_pred,y_true):\n",
    "    preds1=F.softmax(torch.tensor(y_pred,dtype=torch.float32),-1)[:,1].numpy()\n",
    "    return {'metric':-roc_auc_score(y_true[:,-1], preds1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLoss():\n",
    "    def __init__(self,weight,mweight=1.):\n",
    "        self.weight=weight\n",
    "        self.mweight=mweight\n",
    "    def __call__(self,y_pred,y_true):\n",
    "        w=torch.ones_like(y_pred[0])\n",
    "        w[1]=self.mweight\n",
    "#         w=w/w.mean()\n",
    "        return self.weight*F.binary_cross_entropy_with_logits(y_pred[:,1],y_true[:,1].to(torch.float32),weight=torch.tensor(1.,device=device))+\\\n",
    "               (1-self.weight)*F.cross_entropy(y_pred,y_true[:,0],weight=w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([HairTransform(1.0),transforms.RandomRotation(45),\n",
    "                              transforms.RandomHorizontalFlip(p=0.5),transforms.RandomVerticalFlip(p=0.5),\n",
    "                              transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.1),\n",
    "                              transforms.RandomResizedCrop((400,600), scale=(0.7, 1.1)),\n",
    "                              transforms.ToTensor(),CutoutTransform(0.5,24,fill_const=False),\n",
    "                              CutoutTransform(0.5,16,fill_const=False)])\n",
    "\n",
    "transform_val=transforms.Compose([transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_in_rep=7\n",
    "reps =3\n",
    "num_epochs=epoch_in_rep*reps\n",
    "batch_size=24\n",
    "accumulation_steps=1\n",
    "reps_lr=[3e-4*batch_size/24,1e-4*batch_size/24,0.3e-4*batch_size/24]\n",
    "pos_mul=1\n",
    "epoch_mul=1\n",
    "for SEED in SEEDS:\n",
    "    val_folds, train_folds, patients_val = create_folds_extra(train_df,num_folds,SEED)\n",
    "    for fold in range(num_folds): \n",
    "        torch.manual_seed(SEED+fold+add_seed)\n",
    "        np.random.seed(SEED+fold+add_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        validate_ds=D.Subset(ImageDataset(params.path.train_jpg_small,\n",
    "                                          train_df,transform=transform_val,return_years=False),val_folds[fold])\n",
    "        train_ds=D.Subset(ImageDataset(params.path.train_jpg_small,\n",
    "                                       train_df,transform=transform,meta_aug=0.1,return_years=False),train_folds[fold])#model_type='efficientnet_b0'\n",
    "        sample_weights=np.ones(len(train_ds))\n",
    "        sample_weights=sample_weights+train_df.target.values[train_folds[fold]]*(pos_mul-1)\n",
    "        epoch_size=(int(epoch_mul*len(train_ds)//pos_mul)//(batch_size*accumulation_steps))*(batch_size*accumulation_steps)\n",
    "        sampler=D.WeightedRandomSampler(sample_weights, epoch_size, replacement=True)\n",
    "        model = get_model(model_type,8,extra=[8,8,[7,32]],mid_extra=128,mlps=[1024,256],dropout=0.5,bn=True).to(device)\n",
    "        name=params.model_format.format(model_type,name_tamplate.format(SEED),1,fold)\n",
    "        print(name)\n",
    "        my_loss=MyLoss(0.01)\n",
    "        #my_loss=my_one_loss\n",
    "        learner = Learner(model,None,loss_func=my_loss,name=name,scheduler=None,device=device)\n",
    "        learner.metric=my_metric\n",
    "        learner.optimizer = torch.optim.Adam(learner.model.parameters(), lr=1e-4)\n",
    "        learner.init_amp()\n",
    "        def new_get_y(self,batch):\n",
    "            return torch.stack(batch[-2:],1)\n",
    "        def new_get_x(self,batch):\n",
    "            return batch[:-2] \n",
    "        learner.get_y=MethodType(new_get_y, learner)\n",
    "        learner.get_x=MethodType(new_get_x, learner)\n",
    "\n",
    "        train_dl_args={'shuffle': False,'sampler':sampler }\n",
    "        for t in range(reps):\n",
    "            learner.scheduler = torch.optim.lr_scheduler.OneCycleLR(learner.optimizer, pct_start=0.01,final_div_factor= 10,\n",
    "                                                                    max_lr=reps_lr[t], \n",
    "                                                                    steps_per_epoch=epoch_size//(batch_size*accumulation_steps)+1, \n",
    "                                                                    epochs=num_epochs//reps)\n",
    "\n",
    "            learner.fit(num_epochs//reps,train_ds,\n",
    "                        validate_ds,\n",
    "                        batch_size=batch_size,\n",
    "                        accumulation_steps=accumulation_steps,\n",
    "                        eval_batch=2*batch_size,\n",
    "                        path=params.path.models,\n",
    "                        train_dl_args=train_dl_args,\n",
    "                        num_workers=12)\n",
    "        sandesh.send({'name':learner.name,'best_metric':learner.best_metric})\n",
    "        print(learner.name,' best metric:',learner.best_metric)\n",
    "        learner.save_model(params.path.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(params.path.data+'test.csv')\n",
    "prepare_df(test_df)\n",
    "test_df=test_df.reset_index(drop=True)\n",
    "\n",
    "test_ds=ImageDataset(params.path.test_jpg_small,test_df,transform=transform)\n",
    "\n",
    "predss=[]\n",
    "for SEED in SEEDS:\n",
    "    for fold in range(num_folds): \n",
    "        torch.manual_seed(SEED+fold+add_seed)\n",
    "        np.random.seed(SEED+fold+add_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        model = get_model(model_type,8,extra=[8,8,[7,32]],mid_extra=128,mlps=[1024,256],dropout=0.4,bn=True,return_features=True).to(device)\n",
    "        name=params.model_format.format(model_type,name_tamplate.format(SEED),1,fold)\n",
    "        print(name)\n",
    "        my_loss=MyLoss(0.01)\n",
    "        learner = Learner(model,None,loss_func=my_loss,name=name,scheduler=None,device=device)\n",
    "        learner.metric=my_metric\n",
    "        learner.load_model(params.path.models)\n",
    "        learner.init_amp()\n",
    "        def new_get_x(self,batch):\n",
    "            return batch\n",
    "        learner.get_x=MethodType(new_get_x, learner)\n",
    "        featuress=[]\n",
    "        for i in range(16):\n",
    "            y_pred=learner.predict(test_ds,batch_size=64,num_workers=16)\n",
    "            predss.append(y_pred[0])\n",
    "            featuress.append(y_pred[1])\n",
    "        with open(params.path.features+(name.split('.')[0]+'_test.pkl'),'wb') as f:\n",
    "            pickle.dump(np.stack(featuress,0),f,protocol=4)\n",
    "with open(params.path.output+output_name,'wb') as f:\n",
    "    pickle.dump(predss,f,protocol=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.nanmean(np.stack(predss,0),0)\n",
    "preds2=F.softmax(torch.tensor(y_pred,dtype=torch.float32),-1)[:,1].numpy()\n",
    "\n",
    "\n",
    "preds2.min()\n",
    "preds2.max()\n",
    "preds2.std()\n",
    "_=plt.hist(preds2,bins=30)\n",
    "\n",
    "sub=pd.read_csv(params.path.data+'sample_submission.csv')\n",
    "\n",
    "sub['image_name']=test_df['image_name']\n",
    "sub['target']=preds2\n",
    "sub.head(10)\n",
    "sub.to_csv(params.path.output+'/submission102.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
